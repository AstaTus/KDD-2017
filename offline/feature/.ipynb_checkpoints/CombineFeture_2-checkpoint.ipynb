{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link_df = pd.read_csv('../../data/original/links (table 3).csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather1_df = pd.read_csv('../../data/preprocess/preprocess_weather1.csv', index_col=0)\n",
    "weather2_df = pd.read_csv('../../data/preprocess/preprocess_weather2.csv', index_col=0)\n",
    "weather3_df = pd.read_csv('../../data/preprocess/preprocess_weather3.csv', index_col=0)\n",
    "weather4_df = pd.read_csv('../../data/preprocess/preprocess_weather4.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weekdayOneHotEncoder(series):\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    enc.fit([[0], [1], [2], [3], [4], [5], [6]])\n",
    "    weekdays = []\n",
    "    for t in series.values:\n",
    "        weekdays.append([t])\n",
    "    return enc.transform(weekdays).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def directionOneHotEncoder(series):\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    enc.fit([[0], [1], [2], [3], [4], [5], [6], [7], [8]])\n",
    "    directions = []\n",
    "    for t in series.values:\n",
    "        directions.append([t])\n",
    "    return enc.transform(directions).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练集 2016-07-19~2016-09-05 \n",
    "# 测试集 2016-09-06~2016-09-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_start_date = pd.to_datetime('2016-7-19')\n",
    "# train_end_date = pd.to_datetime('2016-9-05')\n",
    "# test_start_date = pd.to_datetime('2016-9-06')\n",
    "# test_end_date = pd.to_datetime('2016-9-12')\n",
    "# export_path = '../../data/offline/validation_9_6/'\n",
    "\n",
    "# train_start_date = pd.to_datetime('2016-7-19')\n",
    "# train_end_date = pd.to_datetime('2016-9-19')\n",
    "# test_start_date = pd.to_datetime('2016-9-20')\n",
    "# test_end_date = pd.to_datetime('2016-9-26')\n",
    "# export_path = '../../data/offline/validation_9_20/'\n",
    "\n",
    "train_start_date = pd.to_datetime('2016-7-19')\n",
    "train_end_date = pd.to_datetime('2016-10-10')\n",
    "test_start_date = pd.to_datetime('2016-10-11')\n",
    "test_end_date = pd.to_datetime('2016-10-17')\n",
    "export_path = '../../data/offline/validation_10_11/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_day_count = (test_end_date - train_start_date).days\n",
    "train_day_count = (train_end_date - train_start_date).days\n",
    "test_day_count = (test_end_date - test_start_date).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weekdays = []\n",
    "ranges = pd.date_range(start=train_start_date, end=test_end_date)\n",
    "for d in ranges:\n",
    "    weekdays.append(d.weekday())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morning LINKS 6:00-10:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for link_id in link_df.index:\n",
    "    time_df = pd.read_csv('../../data/process/link_residual_time/morning/'+ str(link_id) + '.csv', index_col=0, parse_dates=True)\n",
    "    time_df = time_df.loc[train_start_date:test_end_date]\n",
    "    \n",
    "    temp_df = pd.merge(time_df, weather1_df, how='left', left_index=True, right_index=True)\n",
    "    time_df = pd.merge(temp_df, weather2_df, how='left', left_index=True, right_index=True)\n",
    "    time_df['weekday'] = weekdays\n",
    "    \n",
    "    train_time_df = time_df.loc[train_start_date:train_end_date]\n",
    "    test_time_df = time_df.loc[test_start_date:test_end_date]\n",
    "    \n",
    "    X_time_df = time_df[['0', '1', '2', '3', '4', '5',\n",
    "                           'pressure_x', 'sea_pressure_x', 'wind_speed_x', 'temperature_x', \n",
    "                           'rel_humidity_x', 'precipitation_x','pressure_y', 'sea_pressure_y', \n",
    "                           'wind_speed_y', 'temperature_y', 'rel_humidity_y', 'precipitation_y',\n",
    "                          ]]\n",
    "    \n",
    "    y_train_time_df = train_time_df[['6', '7', '8', '9', '10', '11']]\n",
    "    y_test_time_df = test_time_df[['6', '7', '8', '9', '10', '11']]\n",
    "    X_test_time_df = test_time_df[['0', '1', '2', '3', '4', '5']]\n",
    "    \n",
    "    tempa = preprocessing.scale(X_time_df)\n",
    "    tempb = weekdayOneHotEncoder(time_df['weekday'])\n",
    "    tempc = directionOneHotEncoder(time_df['wind_direction_x'])\n",
    "    tempd = directionOneHotEncoder(time_df['wind_direction_y']) \n",
    "    temp_df = pd.DataFrame(np.concatenate((tempa, tempb, tempc, tempd), axis=1))\n",
    "    \n",
    "    X_train_df = temp_df.loc[np.array(range(train_day_count + 1))]\n",
    "    X_train_df.to_csv(export_path + 'feature/feature2/morning/X_train_link' + str(link_id) + '.csv')\n",
    "    y_train_df = pd.DataFrame(y_train_time_df.values)\n",
    "    y_train_df.to_csv(export_path + 'feature/feature2/morning/y_train_link' + str(link_id) + '.csv')\n",
    "    \n",
    "    X_test_df = temp_df.loc[np.array(range(train_day_count, train_day_count + test_day_count + 1))]\n",
    "    y_test_df = pd.DataFrame(y_test_time_df.values)\n",
    "    X_test_df.reset_index(drop=True).to_csv(export_path + 'feature/feature2/morning/X_test_link' + str(link_id) + '.csv')\n",
    "    y_test_df.reset_index(drop=True).to_csv(export_path + 'feature/feature2/morning/y_test_link' + str(link_id) + '.csv')\n",
    "    \n",
    "    pd.DataFrame(X_test_time_df.values).reset_index(drop=True).to_csv(export_path + 'feature/feature2/morning/X_src_test_link' + str(link_id) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afternoon LINKS 15:00-19:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for link_id in link_df.index:\n",
    "    time_df = pd.read_csv('../../data/process/link_residual_time/afternoon/'+ str(link_id) + '.csv', index_col=0, parse_dates=True)\n",
    "    time_df = time_df.loc[train_start_date:test_end_date]\n",
    "    \n",
    "    temp_df = pd.merge(time_df, weather1_df, how='left', left_index=True, right_index=True)\n",
    "    time_df = pd.merge(temp_df, weather2_df, how='left', left_index=True, right_index=True)\n",
    "    time_df['weekday'] = weekdays\n",
    "    \n",
    "    train_time_df = time_df.loc[train_start_date:train_end_date]\n",
    "    test_time_df = time_df.loc[test_start_date:test_end_date]\n",
    "    \n",
    "    X_time_df = time_df[['0', '1', '2', '3', '4', '5',\n",
    "                                                   'pressure_x', 'sea_pressure_x', 'wind_speed_x', 'temperature_x', \n",
    "                                                   'rel_humidity_x', 'precipitation_x','pressure_y', 'sea_pressure_y', \n",
    "                                                   'wind_speed_y', 'temperature_y', 'rel_humidity_y', 'precipitation_y']]\n",
    "    \n",
    "    y_train_time_df = train_time_df[['6', '7', '8', '9', '10', '11']]\n",
    "    y_test_time_df = test_time_df[['6', '7', '8', '9', '10', '11']]\n",
    "    X_test_time_df = test_time_df[['0', '1', '2', '3', '4', '5']]\n",
    "    \n",
    "    tempa = preprocessing.scale(X_time_df)\n",
    "    tempb = weekdayOneHotEncoder(time_df['weekday'])\n",
    "    tempc = directionOneHotEncoder(time_df['wind_direction_x'])\n",
    "    tempd = directionOneHotEncoder(time_df['wind_direction_y'])\n",
    "    temp_df = pd.DataFrame(np.concatenate((tempa, tempb, tempc, tempd), axis=1))\n",
    "    \n",
    "    X_train_df = temp_df.loc[np.array(range(train_day_count + 1))]\n",
    "    X_train_df.to_csv(export_path + 'feature/feature2/afternoon/X_train_link' + str(link_id) + '.csv')\n",
    "    y_train_df = pd.DataFrame(y_train_time_df.values)\n",
    "    y_train_df.to_csv(export_path + 'feature/feature2/afternoon/y_train_link' + str(link_id) + '.csv')\n",
    "    \n",
    "    X_test_df = temp_df.loc[np.array(range(train_day_count, train_day_count + test_day_count + 1))]\n",
    "    y_test_df = pd.DataFrame(y_test_time_df.values)\n",
    "    X_test_df.reset_index(drop=True).to_csv(export_path + 'feature/feature2/afternoon/X_test_link' + str(link_id) + '.csv')\n",
    "    y_test_df.reset_index(drop=True).to_csv(export_path + 'feature/feature2/afternoon/y_test_link' + str(link_id) + '.csv')\n",
    "    \n",
    "    pd.DataFrame(X_test_time_df.values).reset_index(drop=True).to_csv(export_path + 'feature/feature2/afternoon/X_src_test_link' + str(link_id) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
