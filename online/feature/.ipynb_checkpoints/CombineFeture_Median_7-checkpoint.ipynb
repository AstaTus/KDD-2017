{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link_df = pd.read_csv('../../data/original/links (table 3).csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather1_df = pd.read_csv('../../data/preprocess/preprocess_weather1.csv', index_col=0)\n",
    "weather2_df = pd.read_csv('../../data/preprocess/preprocess_weather2.csv', index_col=0)\n",
    "weather3_df = pd.read_csv('../../data/preprocess/preprocess_weather3.csv', index_col=0)\n",
    "weather4_df = pd.read_csv('../../data/preprocess/preprocess_weather4.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weekdayOneHotEncoder(series):\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    enc.fit([[0], [1], [2], [3], [4], [5], [6]])\n",
    "    weekdays = []\n",
    "    for t in series.values:\n",
    "        weekdays.append([t])\n",
    "    return enc.transform(weekdays).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def directionOneHotEncoder(series):\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    enc.fit([[0], [1], [2], [3], [4], [5], [6], [7], [8]])\n",
    "    directions = []\n",
    "    for t in series.values:\n",
    "        directions.append([t])\n",
    "    return enc.transform(directions).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transWeekDay(indexs):\n",
    "    weekdays = []\n",
    "    for i in indexs:\n",
    "        weekdays.append(i.weekday())\n",
    "    \n",
    "    return weekdays;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_start_date = pd.to_datetime('2016-7-19')\n",
    "train_end_date = pd.to_datetime('2016-10-17')\n",
    "test_start_date = pd.to_datetime('2016-10-18')\n",
    "test_end_date = pd.to_datetime('2016-10-24')\n",
    "export_path = '../../data/online/'\n",
    "\n",
    "all_day_count = (test_end_date - train_start_date).days\n",
    "train_day_count = (train_end_date - train_start_date).days\n",
    "test_day_count = (test_end_date - test_start_date).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morning LINKS 6:00-10:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for link_id in link_df.index:\n",
    "    time_df = pd.read_csv('../../data/process/link_median_time/morning/'+ str(link_id) + '.csv', index_col=0, parse_dates=True)\n",
    "    minute_time_df = pd.read_csv('../../data/process/link_median_time/morning/minute_'+ str(link_id) + '.csv', index_col=0, parse_dates=True)\n",
    "    time_df = time_df.loc[train_start_date:test_end_date]\n",
    "    y_test_minute_time_df = minute_time_df.loc[test_start_date:test_end_date]\n",
    "\n",
    "    time_df['weekday'] = transWeekDay(time_df.index)\n",
    "\n",
    "\n",
    "    temp_df = pd.merge(time_df, weather1_df, how='left', left_index=True, right_index=True)\n",
    "    time_df = pd.merge(temp_df, weather2_df, how='left', left_index=True, right_index=True)\n",
    "\n",
    "    train_time_df = time_df.loc[train_start_date:train_end_date]\n",
    "    test_time_df = time_df.loc[test_start_date:test_end_date]\n",
    "\n",
    "    X_time_df = time_df[['0', '1', '2', '3', '4', 'weekday',\n",
    "                           'pressure_x', 'sea_pressure_x', 'wind_speed_x', 'temperature_x', \n",
    "                           'rel_humidity_x', 'precipitation_x','pressure_y', 'sea_pressure_y', \n",
    "                           'wind_speed_y', 'temperature_y', 'rel_humidity_y', 'precipitation_y',\n",
    "                          ]]\n",
    "\n",
    "    y_train_time_df = train_time_df['5']\n",
    "    y_test_time_df = test_time_df['5']\n",
    "    X_test_time_df = test_time_df[['0', '1', '2', '3', '4', 'weekday']]\n",
    "\n",
    "    tempa = preprocessing.scale(X_time_df)\n",
    "    tempb = weekdayOneHotEncoder(time_df['weekday'])\n",
    "    tempc = directionOneHotEncoder(time_df['wind_direction_x'])\n",
    "    tempd = directionOneHotEncoder(time_df['wind_direction_y'])\n",
    "    temp_df = pd.DataFrame(np.concatenate((tempa, tempb, tempc, tempd), axis=1))\n",
    "\n",
    "    X_train_df = temp_df.loc[np.array(range(len(y_train_time_df)))]\n",
    "    X_train_df.to_csv(export_path + 'feature/feature7/morning/X_train_link' + str(link_id) + '.csv')\n",
    "    y_train_df = pd.DataFrame(y_train_time_df.values)\n",
    "    y_train_df.to_csv(export_path + 'feature/feature7/morning/y_train_link' + str(link_id) + '.csv')\n",
    "\n",
    "    X_test_df = temp_df.loc[np.array(range(len(y_train_time_df), len(y_train_time_df) + test_day_count + 1))]\n",
    "    y_test_df = pd.DataFrame(y_test_time_df.values)\n",
    "    X_test_df.reset_index(drop=True).to_csv(export_path + 'feature/feature7/morning/X_test_link' + str(link_id) + '.csv')\n",
    "    y_test_df.reset_index(drop=True).to_csv(export_path + 'feature/feature7/morning/y_test_link' + str(link_id) + '.csv')\n",
    "    y_test_minute_time_df.reset_index(drop=True).to_csv(export_path + 'feature/feature7/morning/y_test_minute_link' + str(link_id) + '.csv')\n",
    "    \n",
    "    pd.DataFrame(X_test_time_df.values).reset_index(drop=True).to_csv(export_path + 'feature/feature7/morning/X_src_test_link' + str(link_id) + '.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afternoon LINKS 15:00-19:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for link_id in link_df.index:\n",
    "    time_df = pd.read_csv('../../data/process/link_median_time/afternoon/'+ str(link_id) + '.csv', index_col=0, parse_dates=True)\n",
    "    minute_time_df = pd.read_csv('../../data/process/link_median_time/afternoon/minute_'+ str(link_id) + '.csv', index_col=0, parse_dates=True)\n",
    "    time_df = time_df.loc[train_start_date:test_end_date]\n",
    "    y_test_minute_time_df = minute_time_df.loc[test_start_date:test_end_date]\n",
    "    \n",
    "    time_df['weekday'] = transWeekDay(time_df.index)\n",
    "    \n",
    "    temp_df = pd.merge(time_df, weather1_df, how='left', left_index=True, right_index=True)\n",
    "    time_df = pd.merge(temp_df, weather2_df, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    train_time_df = time_df.loc[train_start_date:train_end_date]\n",
    "    test_time_df = time_df.loc[test_start_date:test_end_date]\n",
    "    \n",
    "    X_time_df = time_df[['0', '1', '2', '3', '4', 'weekday',\n",
    "                           'pressure_x', 'sea_pressure_x', 'wind_speed_x', 'temperature_x', \n",
    "                           'rel_humidity_x', 'precipitation_x','pressure_y', 'sea_pressure_y', \n",
    "                           'wind_speed_y', 'temperature_y', 'rel_humidity_y', 'precipitation_y']]\n",
    "    \n",
    "    y_train_time_df = train_time_df['5']\n",
    "    y_test_time_df = test_time_df['5']\n",
    "    X_test_time_df = test_time_df[['0', '1', '2', '3',  '4','weekday']]\n",
    "    \n",
    "    tempa = preprocessing.scale(X_time_df)\n",
    "    tempb = weekdayOneHotEncoder(time_df['weekday'])\n",
    "    tempc = directionOneHotEncoder(time_df['wind_direction_x'])\n",
    "    tempd = directionOneHotEncoder(time_df['wind_direction_y'])\n",
    "    temp_df = pd.DataFrame(np.concatenate((tempa, tempb, tempc, tempd), axis=1))\n",
    "    \n",
    "    X_train_df = temp_df.loc[np.array(range(len(y_train_time_df)))]\n",
    "    X_train_df.to_csv(export_path + 'feature/feature7/afternoon/X_train_link' + str(link_id) + '.csv')\n",
    "    y_train_df = pd.DataFrame(y_train_time_df.values)\n",
    "    y_train_df.to_csv(export_path + 'feature/feature7/afternoon/y_train_link' + str(link_id) + '.csv')\n",
    "    \n",
    "    X_test_df = temp_df.loc[np.array(range(len(y_train_time_df), len(y_train_time_df) + test_day_count + 1))]\n",
    "    y_test_df = pd.DataFrame(y_test_time_df.values)\n",
    "    X_test_df.reset_index(drop=True).to_csv(export_path + 'feature/feature7/afternoon/X_test_link' + str(link_id) + '.csv')\n",
    "    y_test_df.reset_index(drop=True).to_csv(export_path + 'feature/feature7/afternoon/y_test_link' + str(link_id) + '.csv')\n",
    "    y_test_minute_time_df.reset_index(drop=True).to_csv(export_path + 'feature/feature7/afternoon/y_test_minute_link' + str(link_id) + '.csv')\n",
    "    \n",
    "    pd.DataFrame(X_test_time_df.values).reset_index(drop=True).to_csv(export_path + 'feature/feature7/afternoon/X_src_test_link' + str(link_id) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
