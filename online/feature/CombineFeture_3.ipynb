{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weekdayOneHotEncoder(series):\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    enc.fit([[0], [1], [2], [3], [4], [5], [6]])\n",
    "    weekdays = []\n",
    "    for t in series.values:\n",
    "        weekdays.append([t])\n",
    "    return enc.transform(weekdays).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def directionOneHotEncoder(series):\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    enc.fit([[0], [1], [2], [3], [4], [5], [6], [7], [8]])\n",
    "    directions = []\n",
    "    for t in series.values:\n",
    "        directions.append([t])\n",
    "    return enc.transform(directions).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_start_date = pd.to_datetime('2016-7-19')\n",
    "# train_end_date = pd.to_datetime('2016-9-05')\n",
    "# test_start_date = pd.to_datetime('2016-9-06')\n",
    "# test_end_date = pd.to_datetime('2016-9-12')\n",
    "# export_path = '../../data/offline/validation_9_5/'\n",
    "\n",
    "# train_start_date = pd.to_datetime('2016-7-19')\n",
    "# train_end_date = pd.to_datetime('2016-9-19')\n",
    "# test_start_date = pd.to_datetime('2016-9-20')\n",
    "# test_end_date = pd.to_datetime('2016-9-26')\n",
    "# export_path = '../../data/offline/validation_9_20/'\n",
    "\n",
    "train_start_date = pd.to_datetime('2016-7-19')\n",
    "train_end_date = pd.to_datetime('2016-10-17')\n",
    "test_start_date = pd.to_datetime('2016-10-18')\n",
    "test_end_date = pd.to_datetime('2016-10-24')\n",
    "export_path = '../../data/online/'\n",
    "\n",
    "all_day_count = (test_end_date - train_start_date).days\n",
    "train_day_count = (train_end_date - train_start_date).days\n",
    "test_day_count = (test_end_date - test_start_date).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weekdays = []\n",
    "ranges = pd.date_range(start=train_start_date, end=test_end_date)\n",
    "for d in ranges:\n",
    "    weekdays.append(d.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather1_df = pd.read_csv('../../data/preprocess/preprocess_weather1.csv', index_col=0)\n",
    "weather2_df = pd.read_csv('../../data/preprocess/preprocess_weather2.csv', index_col=0)\n",
    "weather3_df = pd.read_csv('../../data/preprocess/preprocess_weather3.csv', index_col=0)\n",
    "weather4_df = pd.read_csv('../../data/preprocess/preprocess_weather4.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "routes = pd.read_csv('../../data/original/routes (table 4).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morninig_routes_times = []\n",
    "afternoon_routes_times = []\n",
    "\n",
    "for i in routes.index:\n",
    "    link_seq = routes.loc[i]['link_seq']\n",
    "    links = link_seq.split(',')\n",
    "    \n",
    "    morning_time_df = None\n",
    "    for k, link_id in enumerate(links):\n",
    "        if k == 0:\n",
    "            morning_time_df = pd.read_csv('../../data/process/link_residual_time/morning/'+ str(link_id) + '.csv', index_col=0, parse_dates=True)\n",
    "        else:\n",
    "            morning_time_df += pd.read_csv('../../data/process/link_residual_time/morning/'+ str(link_id) + '.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "    afternoon_time_df = None\n",
    "    for k, link_id in enumerate(links):\n",
    "        if k == 0:\n",
    "            afternoon_time_df = pd.read_csv('../../data/process/link_residual_time/afternoon/'+ str(link_id) + '.csv', index_col=0, parse_dates=True)\n",
    "        else:\n",
    "            afternoon_time_df += pd.read_csv('../../data/process/link_residual_time/afternoon/'+ str(link_id) + '.csv', index_col=0, parse_dates=True)\n",
    "            \n",
    "    morninig_routes_times.append(morning_time_df)\n",
    "    afternoon_routes_times.append(afternoon_time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m_rt in morninig_routes_times:\n",
    "    m_rt['std'] = m_rt[['0', '1', '2', '3', '4', '5']].std(axis=1)\n",
    "    m_rt['mean'] = m_rt[['0', '1', '2', '3', '4', '5']].mean(axis=1)\n",
    "    \n",
    "for a_rt in afternoon_routes_times:\n",
    "    a_rt['std'] = a_rt[['0', '1', '2', '3', '4', '5']].std(axis=1)\n",
    "    a_rt['mean'] = a_rt[['0', '1', '2', '3', '4', '5']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in routes.index:\n",
    "    time_df = morninig_routes_times[i]\n",
    "    time_df = time_df.loc[train_start_date:test_end_date]\n",
    "\n",
    "    temp_df = pd.merge(time_df, weather1_df, how='left', left_index=True, right_index=True)\n",
    "    time_df = pd.merge(temp_df, weather2_df, how='left', left_index=True, right_index=True)\n",
    "    time_df['weekday'] = weekdays\n",
    "\n",
    "    train_time_df = time_df.loc[train_start_date:train_end_date]\n",
    "\n",
    "    X_time_df = time_df[['0', '1', '2', '3', '4', '5','std', 'mean',\n",
    "                           'pressure_x', 'sea_pressure_x', 'wind_speed_x', 'temperature_x', \n",
    "                           'rel_humidity_x', 'precipitation_x','pressure_y', 'sea_pressure_y', \n",
    "                           'wind_speed_y', 'temperature_y', 'rel_humidity_y', 'precipitation_y',\n",
    "                          ]]\n",
    "\n",
    "    y_train_time_df = train_time_df[['6', '7', '8', '9', '10', '11']]\n",
    "\n",
    "    tempa = preprocessing.scale(X_time_df)\n",
    "    tempb = weekdayOneHotEncoder(time_df['weekday'])\n",
    "    tempc = directionOneHotEncoder(time_df['wind_direction_x'])\n",
    "    tempd = directionOneHotEncoder(time_df['wind_direction_y']) \n",
    "    temp_df = pd.DataFrame(np.concatenate((tempa, tempb, tempc, tempd), axis=1))\n",
    "\n",
    "    X_train_df = temp_df.loc[np.array(range(train_day_count + 1))]\n",
    "    X_train_df.to_csv(export_path + 'feature/feature3/morning/X_train_route' + str(i) + '.csv')\n",
    "    y_train_df = pd.DataFrame(y_train_time_df.values)\n",
    "    y_train_df.to_csv(export_path + 'feature/feature3/morning/y_train_route' + str(i) + '.csv')\n",
    "\n",
    "    X_test_df = temp_df.loc[np.array(range(train_day_count, train_day_count + test_day_count + 1))]\n",
    "    X_test_df.reset_index(drop=True).to_csv(export_path + 'feature/feature3/morning/X_test_route' + str(i) + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in routes.index:\n",
    "    time_df = afternoon_routes_times[i]\n",
    "    time_df = time_df.loc[train_start_date:test_end_date]\n",
    "\n",
    "    temp_df = pd.merge(time_df, weather1_df, how='left', left_index=True, right_index=True)\n",
    "    time_df = pd.merge(temp_df, weather2_df, how='left', left_index=True, right_index=True)\n",
    "    time_df['weekday'] = weekdays\n",
    "\n",
    "    train_time_df = time_df.loc[train_start_date:train_end_date]\n",
    "\n",
    "    X_time_df = time_df[['0', '1', '2', '3', '4', '5','std', 'mean',\n",
    "                           'pressure_x', 'sea_pressure_x', 'wind_speed_x', 'temperature_x', \n",
    "                           'rel_humidity_x', 'precipitation_x','pressure_y', 'sea_pressure_y', \n",
    "                           'wind_speed_y', 'temperature_y', 'rel_humidity_y', 'precipitation_y',\n",
    "                          ]]\n",
    "\n",
    "    y_train_time_df = train_time_df[['6', '7', '8', '9', '10', '11']]\n",
    "\n",
    "    tempa = preprocessing.scale(X_time_df)\n",
    "    tempb = weekdayOneHotEncoder(time_df['weekday'])\n",
    "    tempc = directionOneHotEncoder(time_df['wind_direction_x'])\n",
    "    tempd = directionOneHotEncoder(time_df['wind_direction_y']) \n",
    "    temp_df = pd.DataFrame(np.concatenate((tempa, tempb, tempc, tempd), axis=1))\n",
    "\n",
    "    X_train_df = temp_df.loc[np.array(range(train_day_count + 1))]\n",
    "    X_train_df.to_csv(export_path + 'feature/feature3/afternoon/X_train_route' + str(i) + '.csv')\n",
    "    y_train_df = pd.DataFrame(y_train_time_df.values)\n",
    "    y_train_df.to_csv(export_path + 'feature/feature3/afternoon/y_train_route' + str(i) + '.csv')\n",
    "\n",
    "    X_test_df = temp_df.loc[np.array(range(train_day_count, train_day_count + test_day_count + 1))]\n",
    "    X_test_df.reset_index(drop=True).to_csv(export_path + 'feature/feature3/afternoon/X_test_route' + str(i) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
